{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7878dc9d",
   "metadata": {},
   "source": [
    "# Evaluation using RAGAS \n",
    "- https://docs.ragas.io/en/stable/howtos/integrations/langchain/#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import langchain\n",
    "import ragas\n",
    "\n",
    "# Environment and configuration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Hugging Face datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# LangChain core components\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# RAGAS evaluation\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    ContextPrecision,\n",
    "    ContextRecall,\n",
    "    ContextRelevance,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity,\n",
    "    ResponseRelevancy,\n",
    "    Faithfulness,\n",
    "    ResponseGroundedness,\n",
    ")\n",
    "\n",
    "print(f\"LangChain Version: {langchain.__version__}\")\n",
    "print(f\"Ragas Version: {ragas.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4cb50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jongb\\dev\\jb_langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Version: 0.3.26\n",
      "Ragas Version: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "# Load API KEY information\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbed42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load synthetic dataset\n",
    "df = pd.read_csv(\"./ragas_synthetic_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddd63d",
   "metadata": {},
   "source": [
    "### Load Sythetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./ragas_synthetic_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets is a library developed by Hugging Face that provides tools for easily loading and processing datasets for machine learning.\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3844a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12/12 [00:00<00:00, 1499.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name'],\n",
      "    num_rows: 12\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert strings in context column into List\n",
    "import ast\n",
    "\n",
    "\n",
    "def convert_to_list(example):\n",
    "    reference_contexts = ast.literal_eval(example[\"reference_contexts\"])\n",
    "    return {\"reference_contexts\": reference_contexts}\n",
    "\n",
    "\n",
    "test_dataset = test_dataset.map(convert_to_list)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D.gov 이슈분석 / 2024-06호 /\\n2  ❘ \\n「D.gov 이슈분석」은 정부의 디지털 전환을 위한 다양한 이슈 분석과 향후 정책 \\n방향을 모색하기 위해 한국지능정보사회진흥원에서 기획․발간하는 보고서입니다.\\n한국지능정보사회진흥원의 사전 승인 없이 본 보고서의 무단전재나 복제를 금하며, \\n가공·인용할 때는 반드시 출처를 명시하여 주시기 바랍니다.\\n본 보고서의 내용은 한국지능정보사회진흥원의 공식 견해와 다를 수 있으며, 문의 \\n및 제안은 아래 연락처로 해 주시기 바랍니다.\\n■ 발행처: 한국지능정보사회진흥원\\n■ 발행인: 황종성\\n■ 작성자: 한국지능정보사회진흥원 디지털플랫폼정부본부 정책기획팀\\n          - 송지향 책임(jhsong@nia.or.kr)\\n          - 박슬기 선임(psk64@nia.or.kr) \\n■ 보고서 온라인 서비스: www.nia.or.kr']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1][\"reference_contexts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87d010",
   "metadata": {},
   "source": [
    "## Simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0aade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = r\"C:\\Users\\jongb\\dev\\jb_langchain\\assets\\250620_해외_디지털정부_전문조직_심층분석_및_시사점.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pre-processing\n",
    "# Step 1: Load Document\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "docs = loader.load()\n",
    "\n",
    "# Step 2: Split Documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Step 3: Embedding\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Step 4: Create Vector DB and Save Embedded Chunks\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "\n",
    "### RAG Run Time\n",
    "\n",
    "# Step 5: Create Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 6: Create Prompt Template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "\n",
    "    Answer in KOREAN.\n",
    "\n",
    "    # CONTEXT \n",
    "    {context}\n",
    "\n",
    "    # QUESTION\n",
    "    {question}\n",
    "\n",
    "    # ANSWER: \n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Step 7: Define LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Step 8: Build Chain\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb22075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(relevant_docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a14750",
   "metadata": {},
   "source": [
    "### Create Batch dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aab529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can you provide an overview of the digital government specialized organizations in the 영국 as mentioned in the 2024-6호 report?',\n",
       " 'Who is 박슬기 in the context of the D.gov 이슈분석 report?',\n",
       " '영국 GDS는 어떤 역할을 하나요?']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create batch dataset including retrieved context for each question\n",
    "batch_dataset = []\n",
    "retrieved_contexts = []\n",
    "for question in test_dataset[\"user_input\"]:\n",
    "    # Search context for each question\n",
    "    contexts = retriever.invoke(question)\n",
    "\n",
    "    retrieved_docs = [doc.page_content for doc in contexts]\n",
    "    retrieved_contexts.append(retrieved_docs)\n",
    "    # Store question and retrieved context together\n",
    "    batch_dataset.append({\"question\": question, \"context\": format_docs(contexts)})\n",
    "\n",
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2cbf8",
   "metadata": {},
   "source": [
    "### Generate answer by calling batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Generate answers using existing chain\n",
    "answer = chain.batch(batch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3b4e0",
   "metadata": {},
   "source": [
    "### For RAGAS Evaluation, the Evaluation dataset must contain the following 4 columns:\n",
    " -\"user_input\"\n",
    " -\"retrieved_contexts\"\n",
    " -\"response\"\n",
    " -\"reference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56be586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add response column\n",
    "if \"response\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"response\"]).add_column(\n",
    "        \"response\", answer\n",
    "    )\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    test_dataset = test_dataset.add_column(\"response\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, add retrieved_contexts column\n",
    "if \"retrieved_contexts\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"retrieved_contexts\"]).add_column(\n",
    "        \"retrieved_contexts\", retrieved_contexts\n",
    "    )\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column(\"retrieved_contexts\", retrieved_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "494937f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name', 'response', 'retrieved_contexts'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992b04a",
   "metadata": {},
   "source": [
    "## RAG Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b816fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "Evaluating_RAG_metrics = [\n",
    "    ContextPrecision(llm=evaluator_llm),\n",
    "    ContextRecall(llm=evaluator_llm),\n",
    "    ContextRelevance(llm=evaluator_llm),\n",
    "    ContextEntityRecall(llm=evaluator_llm),\n",
    "    NoiseSensitivity(llm=evaluator_llm),\n",
    "    ResponseRelevancy(llm=evaluator_llm),\n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    ResponseGroundedness(llm=evaluator_llm),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf7d9fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  97%|█████████▋| 93/96 [03:03<00:33, 11.14s/it]Exception raised in Job[28]: TimeoutError()\n",
      "Evaluating:  99%|█████████▉| 95/96 [03:31<00:13, 13.67s/it]Exception raised in Job[68]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 96/96 [03:33<00:00,  2.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.7384, 'context_recall': 0.6895, 'nv_context_relevance': 1.0000, 'context_entity_recall': 0.2805, 'noise_sensitivity(mode=relevant)': 0.4049, 'answer_relevancy': 0.8976, 'faithfulness': 0.8075, 'nv_response_groundedness': 0.8958}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_rag_result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=Evaluating_RAG_metrics,\n",
    "    # llm=evaluator_llm,\n",
    ")\n",
    "eval_rag_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b03e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rag_df = eval_rag_result.to_pandas()\n",
    "eval_rag_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
