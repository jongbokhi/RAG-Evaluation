{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e48e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries for synthetic dataset generation using RAGAS\n",
    "\n",
    "# Core libraries for version checking\n",
    "import langchain\n",
    "import ragas\n",
    "\n",
    "# Environment and configuration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Document processing libraries\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# RAGAS wrappers for LLM and embeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "# OpenAI integration\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "print(f\"LangChain Version: {langchain.__version__}\")\n",
    "print(f\"Ragas Version: {ragas.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jongb\\dev\\jb_langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Version: 0.3.26\n",
      "Ragas Version: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "# Load API keys from environment file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb97d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the file path for document processing\n",
    "FILE_PATH = \"Your file path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document preprocessing pipeline\n",
    "# Step 1: Load PDF document using PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "docs = loader.load()\n",
    "\n",
    "# Step 2: Split text into chunks for better processing\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "print(f\"Number of document chunks: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c69681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check document metadata structure\n",
    "print(\"Document metadata:\", docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188474f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM and embeddings for synthetic dataset generation\n",
    "# Set up the generator LLM (using GPT-4 turbo mini for cost efficiency)\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "# Set up embeddings model for semantic understanding\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(\n",
    "    OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d2c07",
   "metadata": {},
   "source": [
    "## Generate Sythetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5acd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic test dataset using RAGAS\n",
    "# Initialize the test set generator with configured LLM and embeddings\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "# Generate synthetic dataset from the loaded documents\n",
    "# This creates question-answer pairs and evaluation scenarios\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs,\n",
    "    testset_size=10,  # Number of synthetic samples to generate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956bf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:   0%|          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]        Node c9590b5a-6b4d-4573-a7fd-10b337804b99 does not have a summary. Skipping filtering.\n",
      "Node f97715ec-b514-4dea-ae33-8851e12d964e does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   3%|▎         | 3/100 [00:00<00:18,  5.28it/s]Node 3511447e-750e-4036-aec3-7a6a5243272b does not have a summary. Skipping filtering.\n",
      "Node af3c2804-debf-40b5-a590-54c08807c8d9 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  12%|█▏        | 12/100 [00:00<00:04, 21.92it/s]Node 48acd8b6-bd9b-498f-b055-c96e1e814ef8 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  22%|██▏       | 22/100 [00:01<00:03, 23.78it/s]Node 71852507-0f34-4e75-a808-624463835db3 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  42%|████▏     | 42/100 [00:02<00:02, 21.66it/s]Node 0da916dd-7f02-4db1-89e3-c0062936279e does not have a summary. Skipping filtering.\n",
      "Node 1a616fcb-b7a9-44db-9e5a-b95ecce3e320 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  50%|█████     | 50/100 [00:02<00:01, 32.60it/s]Node 90e4623a-9572-4435-872c-33de84316370 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  74%|███████▍  | 74/100 [00:03<00:01, 20.80it/s]Node 365544a8-98b0-4e13-9a44-934771b9b676 does not have a summary. Skipping filtering.\n",
      "Node 6b5de741-ebe4-4f6d-bef5-1973d4dae039 does not have a summary. Skipping filtering.\n",
      "Node 44a63ce3-6d3c-4954-9e1b-98ecbc16c6df does not have a summary. Skipping filtering.\n",
      "Node ca6c71de-5bd3-4009-84cb-829332e6ee35 does not have a summary. Skipping filtering.\n",
      "Node 08137804-e014-40c6-9417-8fff5248023d does not have a summary. Skipping filtering.\n",
      "Node d76133d7-d85f-4bc5-b15d-02dd7fdd0c66 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  83%|████████▎ | 83/100 [00:03<00:00, 31.17it/s]Node 8ee49a7f-6f2c-4bc5-86c9-14e930bf844d does not have a summary. Skipping filtering.\n",
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.20it/s]                                             \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:38<00:00, 12.76s/it]\n",
      "Generating Samples: 100%|██████████| 12/12 [00:05<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert the generated dataset to pandas DataFrame for easier analysis\n",
    "df = dataset.to_pandas()\n",
    "print(\"Synthetic dataset generated successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated synthetic dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbaa94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the synthetic dataset to CSV file for future use\n",
    "df.to_csv(\"./ragas_synthetic_dataset.csv\", index=False)\n",
    "print(\"Dataset saved to 'ragas_synthetic_dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
